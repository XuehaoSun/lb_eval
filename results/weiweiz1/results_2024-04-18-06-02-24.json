{
    "config_general": {
        "lighteval_sha": "1.14",
        "num_few_shot_default": null,
        "num_fewshot_seeds": null,
        "override_batch_size": null,
        "max_samples": null,
        "job_id": -1,
        "start_time": null,
        "end_time": "2024-04-18-06-02-24",
        "total_evaluation_time_secondes": "",
        "model_name": "weiweiz1/llama-2-7b-hf_autoround_GPTQ",
        "model_sha": "",
        "model_dtype": "4bit",
        "model_size": 1.13
    },
    "results": {
        "harness|winogrande|0": {
            "acc": 0.6866614048934491,
            "acc_stderr": 0.013036512096747983
        },
        "harness|arc:easy|0": {
            "acc": 0.757996632996633,
            "acc_stderr": 0.008788455043255563,
            "acc_norm": 0.7335858585858586,
            "acc_norm_stderr": 0.009071357971078687
        },
        "harness|arc:challenge|0": {
            "acc": 0.4257679180887372,
            "acc_stderr": 0.01444946427886881,
            "acc_norm": 0.4462457337883959,
            "acc_norm_stderr": 0.014526705548539982
        },
        "harness|truthfulqa:mc|0": {
            "mc1": 0.25458996328029376,
            "mc1_stderr": 0.015250117079156494,
            "mc2": 0.3879915853847956,
            "mc2_stderr": 0.013634425301064372
        }
    },
    "task_info": {
        "model": "weiweiz1/llama-2-7b-hf_autoround_GPTQ",
        "revision": "main",
        "private": false,
        "params": 1.13,
        "architectures": "LlamaForCausalLM",
        "quant_type": "GPTQ",
        "precision": "4bit",
        "weight_dtype": "int4",
        "compute_dtype": "bfloat16",
        "hardware": "cpu",
        "status": "Pending",
        "submitted_time": "2024-04-17T14:54:39Z",
        "model_type": "quantization",
        "job_id": -1,
        "job_start_time": null,
        "scripts": "ITREX"
    },
    "quantization_config": {
        "disable_exllama": true,
        "bits": 4,
        "group_size": 128,
        "damp_percent": 0.01,
        "desc_act": false,
        "sym": false,
        "true_sequential": false,
        "model_name_or_path": null,
        "model_file_base_name": "model",
        "quant_method": "gptq"
    },
    "versions": {
        "harness|winogrande|0": 0,
        "harness|arc:easy|0": 0,
        "harness|arc:challenge|0": 0,
        "harness|truthfulqa:mc|0": 1
    }
}