{
    "config_general": {
        "lighteval_sha": "1.4",
        "num_few_shot_default": null,
        "num_fewshot_seeds": null,
        "override_batch_size": null,
        "max_samples": null,
        "job_id": -1,
        "start_time": null,
        "end_time": "2024-09-17-11-52-38",
        "total_evaluation_time_secondes": "",
        "model_name": "Intel/Meta-Llama-3.1-70B-Instruct-int4-inc-private",
        "model_sha": "",
        "model_dtype": "4bit",
        "model_size": 39.79,
        "model_params": 69.04,
        "quant_type": "AutoRound",
        "precision": "4bit"
    },
    "results": {
        "harness|lambada:openai|0": {
            "perplexity,none": 3.064151165876033,
            "perplexity_stderr,none": 0.07378584120276858,
            "acc,none": 0.7550941199301378,
            "acc_stderr,none": 0.005991178005456478,
            "alias": "lambada_openai"
        }
    },
    "task_info": {
        "model": "Intel/Meta-Llama-3.1-70B-Instruct-int4-inc-private",
        "revision": "main",
        "private": false,
        "params": 39.79,
        "architectures": "LlamaForCausalLM",
        "quant_type": "AutoRound",
        "precision": "4bit",
        "model_params": 69.04,
        "model_size": 39.79,
        "weight_dtype": "int4",
        "compute_dtype": "float16",
        "gguf_ftype": "*Q4_0.gguf",
        "hardware": "gpu",
        "status": "Finished",
        "submitted_time": "2024-09-09T15:52:09Z",
        "model_type": "quantization",
        "job_id": -1,
        "job_start_time": null,
        "scripts": "ITREX"
    },
    "quantization_config": {
        "amp": true,
        "autoround_version": "0.3.1.dev",
        "backend": "auto_round:exllamav2",
        "bits": 4,
        "data_type": "int",
        "dataset": "NeelNanda/pile-10k",
        "enable_minmax_tuning": true,
        "enable_norm_bias_tuning": false,
        "enable_quanted_input": true,
        "gradient_accumulate_steps": 1,
        "group_size": 128,
        "iters": 1000,
        "low_gpu_mem_usage": true,
        "lr": 0.001,
        "minmax_lr": 0.001,
        "nsamples": 512,
        "quant_block_list": null,
        "quant_method": "intel/auto-round",
        "scale_dtype": "torch.float16",
        "seqlen": 2048,
        "sym": false,
        "train_bs": 8
    },
    "versions": {
        "harness|lambada:openai|0": 1.0
    },
    "n-shot": {
        "lambada_openai": 0
    },
    "date": 1726540739.9276268,
    "config": {
        "model": "hf",
        "model_args": "pretrained=Intel/Meta-Llama-3.1-70B-Instruct-int4-inc-private,trust_remote_code=True,dtype=float16,_commit_hash=main",
        "batch_size": 1,
        "batch_sizes": [],
        "device": "cuda",
        "use_cache": null,
        "limit": null,
        "bootstrap_iters": 100000,
        "gen_kwargs": null
    }
}