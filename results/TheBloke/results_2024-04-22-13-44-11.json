{
    "config_general": {
        "lighteval_sha": "no",
        "num_few_shot_default": null,
        "num_fewshot_seeds": null,
        "override_batch_size": null,
        "max_samples": null,
        "job_id": -1,
        "start_time": null,
        "end_time": "2024-04-22-13-44-11",
        "total_evaluation_time_secondes": "",
        "model_name": "TheBloke/Llama-2-7B-GGUF",
        "model_sha": "",
        "model_dtype": "4bit",
        "model_size": 7.0
    },
    "results": {
        "harness|piqa|0": {
            "acc,none": 0.7742110990206746,
            "acc_stderr,none": 0.009754980670917335,
            "acc_norm,none": 0.7845484221980413,
            "acc_norm_stderr,none": 0.009592463115658081,
            "alias": "piqa"
        },
        "harness|arc:challenge|0": {
            "acc,none": 0.4257679180887372,
            "acc_stderr,none": 0.014449464278868807,
            "acc_norm,none": 0.44197952218430037,
            "acc_norm_stderr,none": 0.014512682523128342,
            "alias": "arc_challenge"
        },
        "harness|winogrande|0": {
            "acc,none": 0.6842936069455406,
            "acc_stderr,none": 0.01306309474300081,
            "alias": "winogrande"
        },
        "harness|truthfulqa:mc2|0": {
            "acc,none": 0.3879007318210258,
            "acc_stderr,none": 0.013531341480713187,
            "alias": "truthfulqa_mc2"
        }
    },
    "task_info": {
        "model": "TheBloke/Llama-2-7B-GGUF",
        "revision": "main",
        "private": false,
        "params": 7.0,
        "architectures": "?",
        "quant_type": "llama.cpp",
        "precision": "4bit",
        "weight_dtype": "int4",
        "compute_dtype": "bfloat16",
        "gguf_ftype": "*Q4_0.gguf",
        "hardware": "cpu",
        "status": "Pending",
        "submitted_time": "2024-04-22T04:13:19Z",
        "model_type": "quantization",
        "job_id": -1,
        "job_start_time": null,
        "scripts": "llama_cpp"
    },
    "quantization_config": {
        "quant_method": "llama.cpp",
        "ftype": "*Q4_0.gguf"
    },
    "versions": {
        "harness|piqa|0": 1.0,
        "harness|arc:challenge|0": 1.0,
        "harness|winogrande|0": 1.0,
        "harness|truthfulqa:mc2|0": 2.0
    }
}