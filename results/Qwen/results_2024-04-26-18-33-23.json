{
    "config_general": {
        "lighteval_sha": "1.4",
        "num_few_shot_default": null,
        "num_fewshot_seeds": null,
        "override_batch_size": null,
        "max_samples": null,
        "job_id": -1,
        "start_time": null,
        "end_time": "2024-04-26-18-33-23",
        "total_evaluation_time_secondes": "",
        "model_name": "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4",
        "model_sha": "",
        "model_dtype": "4bit",
        "model_size": 8.456,
        "model_params": 16.912,
        "quant_type": "GPTQ",
        "precision": "4bit"
    },
    "results": {
        "harness|winogrande|0": {
            "acc,none": 0.7,
            "acc_stderr,none": 0.10513149660756933,
            "alias": "winogrande"
        }
    },
    "task_info": {
        "model": "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4",
        "revision": "main",
        "private": false,
        "params": 8.456,
        "architectures": "Qwen2ForCausalLM",
        "quant_type": "GPTQ",
        "precision": "4bit",
        "model_params": 16.912,
        "model_size": 8.456,
        "weight_dtype": "int4",
        "compute_dtype": "bfloat16",
        "gguf_ftype": "*Q4_0.gguf",
        "hardware": "gpu",
        "status": "Pending",
        "submitted_time": "2024-04-26T09:50:00Z",
        "model_type": "quantization",
        "job_id": -1,
        "job_start_time": null,
        "scripts": "ITREX"
    },
    "quantization_config": {
        "quant_method": "GPTQ",
        "ftype": "*Q4_0.gguf"
    },
    "versions": {
        "harness|winogrande|0": 1.0
    },
    "n-shot": {
        "winogrande": 0
    },
    "date": 1714127509.7610533,
    "config": {
        "model": "hf",
        "model_args": "pretrained=Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4,dtype=bfloat16,_commit_hash=main",
        "batch_size": 2,
        "batch_sizes": [],
        "device": "cuda",
        "use_cache": null,
        "limit": 20,
        "bootstrap_iters": 100000,
        "gen_kwargs": null
    }
}