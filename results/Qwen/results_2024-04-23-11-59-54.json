{
    "config_general": {
        "lighteval_sha": "1.4",
        "num_few_shot_default": null,
        "num_fewshot_seeds": null,
        "override_batch_size": null,
        "max_samples": null,
        "job_id": -1,
        "start_time": null,
        "end_time": "2024-04-23-11-59-54",
        "total_evaluation_time_secondes": "",
        "model_name": "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4",
        "model_sha": "",
        "model_dtype": "4bit",
        "model_size": 0.197
    },
    "results": {
        "harness|boolq|0": {
            "acc,none": 0.41039755351681956,
            "acc_stderr,none": 0.008603488048617516,
            "alias": "boolq"
        },
        "harness|arc:challenge|0": {
            "acc,none": 0.25426621160409557,
            "acc_stderr,none": 0.012724999945157744,
            "acc_norm,none": 0.2738907849829352,
            "acc_norm_stderr,none": 0.013032004972989505,
            "alias": "arc_challenge"
        },
        "harness|openbookqa|0": {
            "acc,none": 0.194,
            "acc_stderr,none": 0.017701827855304608,
            "acc_norm,none": 0.3,
            "acc_norm_stderr,none": 0.020514426225628053,
            "alias": "openbookqa"
        },
        "harness|arc:easy|0": {
            "acc,none": 0.5218855218855218,
            "acc_stderr,none": 0.010249950427234157,
            "acc_norm,none": 0.47685185185185186,
            "acc_norm_stderr,none": 0.010248782484554471,
            "alias": "arc_easy"
        },
        "harness|piqa|0": {
            "acc,none": 0.6730141458106638,
            "acc_stderr,none": 0.010945157126978234,
            "acc_norm,none": 0.6632208922742111,
            "acc_norm_stderr,none": 0.011026738925251179,
            "alias": "piqa"
        },
        "harness|lambada:openai|0": {
            "perplexity,none": 32.88554061708387,
            "perplexity_stderr,none": 1.614489811207839,
            "acc,none": 0.39705026198331067,
            "acc_stderr,none": 0.0068167186841220865,
            "alias": "lambada_openai"
        },
        "harness|winogrande|0": {
            "acc,none": 0.5516969218626677,
            "acc_stderr,none": 0.013977171307126342,
            "alias": "winogrande"
        },
        "harness|hellaswag|0": {
            "acc,none": 0.3572993427604063,
            "acc_stderr,none": 0.004782246931194991,
            "acc_norm,none": 0.43975303724357695,
            "acc_norm_stderr,none": 0.004953426186069833,
            "alias": "hellaswag"
        }
    },
    "task_info": {
        "model": "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4",
        "revision": "main",
        "private": false,
        "params": 0.197,
        "architectures": "Qwen2ForCausalLM",
        "quant_type": "GPTQ",
        "precision": "4bit",
        "weight_dtype": "int4",
        "compute_dtype": "bfloat16",
        "hardware": "cpu",
        "status": "Pending",
        "submitted_time": "2024-04-19T05:06:08Z",
        "model_type": "quantization",
        "job_id": -1,
        "job_start_time": null,
        "scripts": "ITREX"
    },
    "quantization_config": {
        "batch_size": 1,
        "bits": 4,
        "block_name_to_quantize": null,
        "cache_block_outputs": true,
        "damp_percent": 0.01,
        "dataset": null,
        "desc_act": false,
        "exllama_config": {
            "version": 1
        },
        "group_size": 128,
        "max_input_length": null,
        "model_seqlen": null,
        "module_name_preceding_first_block": null,
        "modules_in_block_to_quantize": null,
        "pad_token_id": null,
        "quant_method": "gptq",
        "sym": true,
        "tokenizer": null,
        "true_sequential": true,
        "use_cuda_fp16": false,
        "use_exllama": false
    },
    "versions": {
        "harness|boolq|0": 2.0,
        "harness|arc:challenge|0": 1.0,
        "harness|openbookqa|0": 1.0,
        "harness|arc:easy|0": 1.0,
        "harness|piqa|0": 1.0,
        "harness|lambada:openai|0": 1.0,
        "harness|winogrande|0": 1.0,
        "harness|hellaswag|0": 1.0
    }
}